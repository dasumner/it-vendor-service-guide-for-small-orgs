AI Services Evaluation Guide
What Youâ€™re Actually Buying
AI services range from simple chatbots to complex document processing to predictive analytics. Most small organizations are being pitched:
	âˆ™	Customer service chatbots (website, phone, email)
	âˆ™	Document processing (invoice extraction, contract review, form filling)
	âˆ™	Content generation (marketing copy, social media, translations)
	âˆ™	Meeting tools (transcription, summarization, action items)
	âˆ™	Predictive analytics (sales forecasting, demand prediction, risk scoring)
What youâ€™re NOT buying:
	âˆ™	Magic that solves all problems
	âˆ™	A replacement for human judgment
	âˆ™	Technology that â€œjust worksâ€ without ongoing management
	âˆ™	Something that will still be cutting-edge in 6 months
Reality check: Most AI vendor claims are 80% hype and 20% substance. Your job is to find that 20%.
The AI Hype Translation Guide



|What Vendor Says       |What It Actually Means                                |What to Ask                                                           |
|-----------------------|------------------------------------------------------|----------------------------------------------------------------------|
|â€œAI-poweredâ€           |We added a chatbot or use an API                      |â€œWhich AI model specifically? Whose?â€                                 |
|â€œMachine learningâ€     |Could be anything from simple rules to actual ML      |â€œWhat are you actually predicting/classifying?â€                       |
|â€œRevolutionary AIâ€     |Weâ€™re using the same OpenAI API as everyone else      |â€œWhatâ€™s proprietary vs. commodity components?â€                        |
|â€œLearns from your dataâ€|May or may not. May use your data to train their model|â€œIs my data used for training? Can I opt out?â€                        |
|â€œ99% accuracyâ€         |Cherry-picked metric that doesnâ€™t reflect real usage  |â€œAccuracy on what task? Whatâ€™s the error rate on [specific use case]?â€|
|â€œExplainable AIâ€       |Buzzword. Can they actually explain decisions?        |â€œShow me an explanation for a real decision.â€                         |
|â€œEnterprise-grade AIâ€  |Meaningless. No definition                            |â€œWhat specific security/compliance standards?â€                        |
|â€œReduces costs by 80%â€ |Theoretical maximum under ideal conditions            |â€œShow me a case study with real numbers.â€                             |

Critical Questions to Ask
Use Case & Value
â€œWhat specific problem does this AI solve that couldnâ€™t be solved without AI?â€
	âˆ™	Good answer: â€œYou process 500 invoices monthly. Human data entry takes 10 min each = 83 hours/month. Our tool extracts data in 30 seconds with 95% accuracy, human reviews in 2 min = 16 hours/month saved.â€
	âˆ™	Red flag: â€œAI transforms your businessâ€ or vague productivity claims
	âˆ™	Why it matters: If they canâ€™t articulate the problem clearly, they donâ€™t have a solution
â€œWhatâ€™s the accuracy rate for our specific use case, and what happens when itâ€™s wrong?â€
	âˆ™	Good answer: â€œFor invoice processing: 95% field-level accuracy on our test set of 1,000 invoices. Errors flagged for human review. We track error types - most are ambiguous handwriting.â€
	âˆ™	Red flag: â€œIndustry-leading accuracyâ€ or â€œIt learns and improves over timeâ€ without numbers
	âˆ™	Why it matters: You need to budget for error correction and understand risk
â€œHow much human oversight is required?â€
	âˆ™	Good answer: â€œInitial setup: 40 hours training data preparation. Ongoing: 10% of outputs require human review, averaging 2 hours/week.â€
	âˆ™	Red flag: â€œFully automatedâ€ or â€œSet it and forget itâ€
	âˆ™	Why it matters: Thereâ€™s no such thing as truly autonomous AI for business-critical tasks
Data & Privacy
â€œWhere does our data go and who has access?â€
	âˆ™	Good answer: â€œData processed in AWS us-east-1, encrypted in transit and at rest. Only you and our SOC 2 certified ops team. Data never leaves your tenant.â€
	âˆ™	Red flag: â€œSecure cloud infrastructureâ€ without specifics
	âˆ™	Why it matters: Youâ€™re liable for data breaches, not them
â€œIs our data used to train or improve your models?â€
	âˆ™	Good answer: â€œNo. Your data is used only for your inferences. We use opt-in anonymized data pools for model improvements with explicit consent.â€
	âˆ™	Red flag: â€œWe use data to improve our serviceâ€ without opt-out, or silence on this topic
	âˆ™	Why it matters: Your sensitive data could train models your competitors use
â€œHow do we get our data back if we cancel?â€
	âˆ™	Good answer: â€œFull data export in JSON/CSV format within 7 days. Includes all inputs, outputs, and audit logs. Complete deletion from our systems within 30 days, certified.â€
	âˆ™	Red flag: â€œWeâ€™ll work with you on thatâ€ or export fees
	âˆ™	Why it matters: Your data held hostage = expensive lock-in
â€œDo you comply with GDPR/CCPA even though weâ€™re not required to?â€
	âˆ™	Good answer: â€œYes, weâ€™re GDPR compliant globally. You can request deletion, export data, and we honor do-not-sell requests.â€
	âˆ™	Red flag: â€œThat doesnâ€™t apply to youâ€ or blank stare
	âˆ™	Why it matters: Privacy regulations are expanding. Better to be ahead than scrambling later
Technical Reality
â€œWhich AI model are you using and is it yours?â€
	âˆ™	Good answer: â€œWe use OpenAIâ€™s GPT-4 API for content generation and our own fine-tuned BERT model for classification, trained on 50K industry-specific examples.â€
	âˆ™	Red flag: â€œProprietary AI technologyâ€ without specifics or â€œAdvanced neural networksâ€
	âˆ™	Why it matters: If itâ€™s just an OpenAI wrapper, youâ€™re overpaying
â€œWhat happens if the underlying AI service (OpenAI, Google, etc.) goes down or changes pricing?â€
	âˆ™	Good answer: â€œWe have fallback to Azure OpenAI. Contract includes price protection - we absorb API cost increases up to 25% for your contract term.â€
	âˆ™	Red flag: â€œThatâ€™s very unlikelyâ€ or no contingency plan
	âˆ™	Why it matters: OpenAI has had outages. Prices have increased. You need a plan.
â€œHow do you prevent hallucinations/false information?â€
	âˆ™	Good answer: â€œWe use RAG (retrieval-augmented generation) grounded in your documents only. Confidence scoring flags uncertain responses. Human review required for high-stakes decisions.â€
	âˆ™	Red flag: â€œOur AI is very reliableâ€ or doesnâ€™t understand the question
	âˆ™	Why it matters: All LLMs hallucinate. Question is how they mitigate it.
â€œCan you show me the AI making a mistake and how you handle it?â€
	âˆ™	Good answer: Shows real error case, explains detection method, describes remediation
	âˆ™	Red flag: â€œOur AI doesnâ€™t make significant errorsâ€ or wonâ€™t demonstrate
	âˆ™	Why it matters: If they canâ€™t show you errors, they donâ€™t know their system well enough
Costs & ROI
â€œWhatâ€™s the total cost of ownership including setup, training, integration, and ongoing monitoring?â€
	âˆ™	Good answer: â€œSetup: $5K (data prep, integration). Monthly: $500 base + $0.10/transaction. Typical client with 1K transactions = $600/month. Expected 6-month ROI based on 20 hours/week saved at $25/hour.â€
	âˆ™	Red flag: â€œStarting at $Xâ€ without full breakdown or usage-based pricing without caps
	âˆ™	Why it matters: AI projects have high hidden costs. Budget for reality, not marketing.
â€œWhat happens if usage exceeds estimates?â€
	âˆ™	Good answer: â€œSoft cap at 2,000 transactions. We alert you at 80%. Overages billed at same $0.10 rate. No surprise bills - you approve increases.â€
	âˆ™	Red flag: â€œUnlimited usageâ€ or exponential overage pricing
	âˆ™	Why it matters: Per-token pricing can explode. You need predictability.
â€œHow long before we see ROI and whatâ€™s your track record?â€
	âˆ™	Good answer: â€œTypical client breaks even month 4-5. Hereâ€™s a case study: [specific client] saved $30K annually, paid $18K year one = $12K net positive, year two $30K positive.â€
	âˆ™	Red flag: â€œImmediate ROIâ€ or â€œIt pays for itselfâ€ without specifics
	âˆ™	Why it matters: AI projects take time to show value. Beware unrealistic promises.
Bias & Fairness
â€œHas your AI been tested for bias relevant to our population?â€
	âˆ™	Good answer: â€œYes, we tested across age, gender, race, income demographics. Found 3% higher error rate for handwritten applications from ages 65+. We implemented additional review for those cases.â€
	âˆ™	Red flag: â€œAI doesnâ€™t have biasâ€ or â€œWe use diverse training dataâ€ without testing
	âˆ™	Why it matters: Biased AI can discriminate illegally and damage your reputation
â€œCan we audit decisions made by the AI?â€
	âˆ™	Good answer: â€œFull audit log: input, output, confidence score, model version, timestamp. You can replay any decision. We provide quarterly bias audits.â€
	âˆ™	Red flag: â€œBlack boxâ€ or â€œProprietary algorithms we canâ€™t shareâ€
	âˆ™	Why it matters: You canâ€™t defend decisions you canâ€™t explain
â€œWhat happens if we discover the AI is making unfair decisions?â€
	âˆ™	Good answer: â€œWe pause the system, investigate root cause, retrain if needed, and compensate for incorrect decisions during that period per our SLA.â€
	âˆ™	Red flag: â€œThatâ€™s very unlikelyâ€ or no plan
	âˆ™	Why it matters: It will happen. You need a response plan.
Evaluation Scorecard



|Category                       |Weight|Score (1-5)|Notes|
|-------------------------------|------|-----------|-----|
|**Problem-Solution Fit**       |25%   |           |     |
|- Clearly defined problem      |      |           |     |
|- AI is appropriate solution   |      |           |     |
|- Measurable success criteria  |      |           |     |
|- Realistic ROI timeline       |      |           |     |
|**Data Governance**            |25%   |           |     |
|- Data security/privacy        |      |           |     |
|- No training on our data      |      |           |     |
|- Clear data ownership         |      |           |     |
|- Export/deletion process      |      |           |     |
|**Technical Credibility**      |20%   |           |     |
|- Specific about models used   |      |           |     |
|- Realistic accuracy claims    |      |           |     |
|- Hallucination prevention     |      |           |     |
|- Failure handling             |      |           |     |
|**Cost Transparency**          |15%   |           |     |
|- Total cost of ownership clear|      |           |     |
|- No surprise pricing          |      |           |     |
|- Realistic ROI projections    |      |           |     |
|- Exit costs reasonable        |      |           |     |
|**Accountability**             |10%   |           |     |
|- Bias testing done            |      |           |     |
|- Audit capabilities           |      |           |     |
|- Error correction process     |      |           |     |
|- Human oversight required     |      |           |     |
|**Vendor Viability**           |5%    |           |     |
|- Financially stable           |      |           |     |
|- Not dependent on single API  |      |           |     |
|- References available         |      |           |     |

Scoring:
	âˆ™	5 = Exceeds expectations
	âˆ™	4 = Meets all requirements
	âˆ™	3 = Acceptable
	âˆ™	2 = Significant concerns
	âˆ™	1 = Unacceptable
Minimum passing score: 3.5 weighted average
Auto-fail criteria:
	âˆ™	Wonâ€™t disclose if they train on your data
	âˆ™	Canâ€™t explain accuracy claims with data
	âˆ™	No audit trail
	âˆ™	â€œFully autonomousâ€ for high-stakes decisions
	âˆ™	Vendor is <1 year old with no track record
Red Flags - AI Edition
Hype Red Flags
	âˆ™	ğŸš© â€œRevolutionary AIâ€ - Itâ€™s probably OpenAIâ€™s API wrapped in a UI
	âˆ™	ğŸš© â€œPowered by neural networksâ€ - Technically true of most AI, tells you nothing
	âˆ™	ğŸš© â€œSelf-learning AIâ€ without explaining what it learns from - Marketing speak
	âˆ™	ğŸš© â€œHuman-level intelligenceâ€ - Absolutely not true for any business AI tool
	âˆ™	ğŸš© â€œExplainable AIâ€ but canâ€™t actually explain a decision - They donâ€™t know what this means
Data & Privacy Red Flags
	âˆ™	ğŸš© Vague about data usage - Assume theyâ€™re training on your data
	âˆ™	ğŸš© â€œData stays secure in the cloudâ€ without specifying where/how - Meaningless
	âˆ™	ğŸš© Canâ€™t explain data retention/deletion - Youâ€™ll never get your data back
	âˆ™	ğŸš© No mention of encryption - Your data is probably stored in plain text
	âˆ™	ğŸš© Requires excessive data access - Theyâ€™re gathering training data, not solving your problem
Technical Red Flags
	âˆ™	ğŸš© â€œProprietary algorithmâ€ for commodity tasks - Itâ€™s not proprietary, theyâ€™re just secretive
	âˆ™	ğŸš© Wonâ€™t name the underlying model - They donâ€™t want you to know itâ€™s basic
	âˆ™	ğŸš© â€œ99%+ accuracyâ€ without explaining on what - Cherry-picked or fictional
	âˆ™	ğŸš© â€œNo hallucinationsâ€ - Every LLM hallucinates. Theyâ€™re lying.
	âˆ™	ğŸš© Canâ€™t demo failure cases - They donâ€™t understand their own system
Cost Red Flags
	âˆ™	ğŸš© â€œPer tokenâ€ pricing without caps - Your bill could be anything
	âˆ™	ğŸš© Free tier that requires credit card - Theyâ€™ll charge you before you realize
	âˆ™	ğŸš© Vague about setup/integration costs - These will exceed the subscription
	âˆ™	ğŸš© ROI claims without case studies - Made up numbers
	âˆ™	ğŸš© â€œSaves X hoursâ€ without accounting for oversight time - Lying about labor savings
Accountability Red Flags
	âˆ™	ğŸš© â€œAI makes unbiased decisionsâ€ - All AI has bias. Question is whether they test for it.
	âˆ™	ğŸš© â€œFully automated decision-makingâ€ for anything important - Illegal in many contexts
	âˆ™	ğŸš© No audit trail - You canâ€™t defend what you canâ€™t explain
	âˆ™	ğŸš© Black box that canâ€™t be questioned - Huge liability risk
	âˆ™	ğŸš© â€œTrust the AIâ€ - Never trust without verification
When NOT to Use AI
Donâ€™t use AI for:
âŒ High-stakes decisions without human review
	âˆ™	Hiring/firing decisions
	âˆ™	Benefits eligibility
	âˆ™	Medical diagnoses
	âˆ™	Legal determinations
	âˆ™	Anything with significant life impact
âŒ Tasks requiring legal/regulatory explainability
	âˆ™	Fair lending decisions
	âˆ™	Civil rights compliance
	âˆ™	Safety-critical systems
	âˆ™	Anywhere you need to justify decisions to regulators
âŒ Small data sets where traditional approaches work
	âˆ™	100 transactions/month doesnâ€™t need AI-powered processing
	âˆ™	Simple if/then rules often work better than ML
âŒ Core competencies where youâ€™ll lose institutional knowledge
	âˆ™	Donâ€™t automate away expertise youâ€™ll need to understand your business
âŒ When you canâ€™t afford to verify outputs
	âˆ™	If you donâ€™t have budget/time for human review, you canâ€™t afford AI
	âˆ™	Garbage in, garbage out - but faster and at scale
âŒ Sensitive contexts where errors cause serious harm
	âˆ™	Child welfare decisions
	âˆ™	Criminal justice
	âˆ™	Medical treatment
	âˆ™	Emergency response (without human verification)
Responsible AI Quick Policy
Before deploying any AI system, ensure you can answer YES to all:
âœ… We have a human who understands how this AI worksâœ… We can explain AI decisions to affected peopleâœ… We have a process to handle AI errorsâœ… Weâ€™ve tested for bias relevant to our populationâœ… We have human review for high-stakes decisionsâœ… We can turn it off if it goes wrongâœ… We own our data and can get it backâœ… Weâ€™ve documented what the AI should/shouldnâ€™t be used for
If you canâ€™t answer yes to all of these, youâ€™re not ready to deploy AI safely.
Real Examples (Anonymized)
Good AI Proposal
Use Case: Automate invoice data entry from scanned vendor invoices
How it works:
	âˆ™	Uses Google Document AI (Vision API) for OCR
	âˆ™	Custom classification model (our proprietary) trained on 10K invoices to extract: vendor, date, amount, line items, tax
	âˆ™	Confidence scoring flags uncertain extractions for human review
Performance:
	âˆ™	Field-level accuracy: 94% (tested on 1,000 held-out invoices)
	âˆ™	15% of invoices flagged for review (poor scan quality or handwritten)
	âˆ™	Processing time: 30 seconds vs. 10 minutes manual
Your data:
	âˆ™	Processed in GCP us-central1, encrypted at rest (AES-256) and in transit (TLS 1.3)
	âˆ™	NOT used for model training
	âˆ™	Full export available anytime as JSON
	âˆ™	Deleted within 30 days of contract termination
Pricing:
	âˆ™	Setup: $3,000 (integration with your accounting system, 40 hours)
	âˆ™	Monthly: $400 base + $0.50/invoice
	âˆ™	Your volume (500/month) = $650/month
	âˆ™	Estimated savings: 70 hours/month at $25/hour = $1,750/month
	âˆ™	ROI: Month 3
SLA:
	âˆ™	99% uptime
	âˆ™	95%+ accuracy or 10% monthly credit
	âˆ™	Accuracy reported monthly with error analysis
References: [Three similar-sized nonprofits]
Why this is good:
	âˆ™	Specific problem, specific solution
	âˆ™	Names actual technology used
	âˆ™	Real accuracy numbers with context
	âˆ™	Clear data handling
	âˆ™	Transparent pricing with realistic ROI
	âˆ™	Enforceable SLA
	âˆ™	Acknowledges limitations (15% need review)
Bad AI Proposal
Transform Your Invoice Processing with AI
InvoiceGenius leverages cutting-edge artificial intelligence and machine learning to revolutionize your accounts payable workflow. Our proprietary neural networks, trained on millions of invoices, deliver human-level accuracy with lightning-fast processing.
Benefits:
	âˆ™	99.9% accuracy
	âˆ™	Reduce costs by up to 90%
	âˆ™	Fully automated processing
	âˆ™	Enterprise-grade security
	âˆ™	Seamless integration
Investment:
Starting at $499/month
Why InvoiceGenius:
	âˆ™	Industry-leading AI technology
	âˆ™	Trusted by thousands of businesses
	âˆ™	Award-winning customer support
	âˆ™	Continuous learning AI that gets smarter over time
Contact us for a personalized demo!
Why this is terrible:
	âˆ™	Pure marketing fluff, zero technical specifics
	âˆ™	â€œProprietary neural networksâ€ - what does this mean?
	âˆ™	â€œ99.9% accuracyâ€ - on what? How measured?
	âˆ™	â€œFully automatedâ€ - dangerous claim
	âˆ™	â€œStarting at $499â€ - what are actual costs?
	âˆ™	No mention of data handling
	âˆ™	â€œHuman-level accuracyâ€ - false claim
	âˆ™	No evidence, no references, no specifics
Real Horror Story
What they sold:
â€œAI-powered customer service that handles 90% of inquiries automatically, reducing support costs by $50K annually.â€
What they delivered:
	âˆ™	Chatbot that could only handle 30% of actual inquiries
	âˆ™	Remaining 70% created frustrated customers AND support tickets
	âˆ™	Training the AI required 200 hours of staff time (not mentioned in proposal)
	âˆ™	Per-conversation pricing hit $2,500/month (they said â€œ$500-1000â€)
	âˆ™	Couldnâ€™t integrate with existing systems, required manual data sync
	âˆ™	â€œAI learningâ€ meant other clientsâ€™ data trained the model
	âˆ™	When they tried to cancel: $5,000 â€œdeployment recovery feeâ€ + 90 days notice
Red flags they missed:
	âˆ™	No demo on their actual customer service data
	âˆ™	Vague â€œ90% automationâ€ claim without proof
	âˆ™	Didnâ€™t ask about training time required
	âˆ™	No pricing cap on usage-based model
	âˆ™	Didnâ€™t review contract termination clause
	âˆ™	Didnâ€™t ask about data sharing between clients
Actual cost: $30K spent over 8 months, 300 hours of staff time, damaged customer relationships. Went back to human support.
Decision Framework
Before you even talk to vendors:
	1.	Define the problem clearly - What exactly are you trying to solve?
	2.	Quantify current cost - How many hours/dollars does this problem cost now?
	3.	Determine acceptable error rate - What % wrong can you tolerate?
	4.	Identify human oversight capacity - Who will review AI outputs?
	5.	Set a realistic budget - Include setup, integration, monitoring, error correction
	6.	Document your data governance requirements - What are your non-negotiables?
Vendor evaluation process:
	1.	RFP with specific questions - Use the questions in this guide
	2.	Require proof, not promises - Live demo on your data, not canned demo
	3.	Check references thoroughly - Ask about problems, not just success
	4.	Pilot before committing - 30-90 day pilot with < 1 year contract
	5.	Legal review - Attorney reviews contract, especially data clauses
Start small:
	âˆ™	Narrow use case - Solve one specific problem, not â€œAI transformationâ€
	âˆ™	Limited data - Donâ€™t give them access to everything upfront
	âˆ™	Human verification - Plan to verify 100% of outputs initially
	âˆ™	Defined success metrics - â€œMust achieve X accuracy on Y task by Z date or we can exitâ€
	âˆ™	Exit strategy - How do you shut this down if it fails?
Red flag threshold:
	âˆ™	1-2 minor red flags - Proceed with caution, get clarification
	âˆ™	3+ minor red flags OR 1 major - Seriously reconsider
	âˆ™	Any auto-fail criteria - Walk away
Remember: AI vendors are incentivized to oversell and under-deliver. Your job is to cut through the hype and determine if thereâ€™s real value. When in doubt, start with a smaller, simpler solution or donâ€™t use AI at all.

Both guides are ready for the repository. Want me to draft any of the templates next (RFP template, evaluation scorecard, reference check questions), or should we move to the CONTRIBUTING.md and CODE_OF_CONDUCT.md files?
